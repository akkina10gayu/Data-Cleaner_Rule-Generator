2025-07-26 16:06:11 - utils.logger - INFO - logger.py:72 - Logging configured - Level: INFO
2025-07-26 16:06:11 - utils.logger - INFO - logger.py:74 - Log file: logs/pipeline_20250726_160611.log
2025-07-26 16:06:11 - src.rule_engine - INFO - rule_engine.py:39 - Loaded rules configuration from config/rules.json
2025-07-26 16:06:11 - __main__ - INFO - main.py:51 - Pipeline initialized with confidence threshold: 0.7
2025-07-26 16:06:11 - __main__ - INFO - main.py:66 - ================================================================================
2025-07-26 16:06:11 - __main__ - INFO - main.py:67 - STARTING DATA CLEANING PIPELINE
2025-07-26 16:06:11 - __main__ - INFO - main.py:68 - ================================================================================
2025-07-26 16:06:11 - __main__ - INFO - main.py:69 - Input file: data/retail_store_sales.csv
2025-07-26 16:06:11 - __main__ - INFO - main.py:70 - Output directory: output
2025-07-26 16:06:11 - __main__ - INFO - main.py:71 - Confidence threshold: 0.7
2025-07-26 16:06:11 - utils.helpers - INFO - helpers.py:32 - Created output directories under output
2025-07-26 16:06:11 - __main__ - INFO - main.py:78 - 
üìÇ STEP 1: Loading and validating input data...
2025-07-26 16:06:11 - __main__ - INFO - main.py:272 -    ‚úì Successfully loaded 12,575 rows and 11 columns
2025-07-26 16:06:11 - __main__ - INFO - main.py:273 -    ‚úì Memory usage: 1.12 MB
2025-07-26 16:06:11 - __main__ - INFO - main.py:274 -    ‚úì Columns: Transaction ID, Customer ID, Category, Item, Price Per Unit, Quantity, Total Spent, Payment Method, Location, Transaction Date, Discount Applied
2025-07-26 16:06:11 - __main__ - INFO - main.py:87 - 
üìä STEP 2: Profiling dataset characteristics...
2025-07-26 16:06:11 - src.data_profiler - INFO - data_profiler.py:43 - Starting dataset profiling for shape: (12575, 11)
2025-07-26 16:06:11 - src.data_profiler - INFO - data_profiler.py:63 - Dataset profiling completed successfully
2025-07-26 16:06:12 - src.data_profiler - INFO - data_profiler.py:498 - Profile report saved to output/data_profile.html
2025-07-26 16:06:12 - src.data_profiler - INFO - data_profiler.py:792 - Profile results saved to output/data_profile.json
2025-07-26 16:06:12 - __main__ - INFO - main.py:101 -    ‚úì Profile completed in 0.95 seconds
2025-07-26 16:06:12 - __main__ - INFO - main.py:102 -    ‚úì Analyzed 11 columns
2025-07-26 16:06:12 - __main__ - INFO - main.py:105 - 
üéØ STEP 3: Matching cleaning rules to fields...
2025-07-26 16:06:12 - src.rule_engine - INFO - rule_engine.py:56 - Starting rule matching analysis...
2025-07-26 16:06:12 - src.rule_engine - WARNING - rule_engine.py:323 - Field 'Item' did not match any field-specific rules
2025-07-26 16:06:12 - src.rule_engine - INFO - rule_engine.py:421 - Applied dataset rule: validate_transaction_totals
2025-07-26 16:06:12 - src.rule_engine - INFO - rule_engine.py:428 - Applied dataset rule: validate_discount_range to field Discount Applied
2025-07-26 16:06:12 - src.rule_engine - INFO - rule_engine.py:82 - Rule matching completed. Matched rules for 12 fields.
2025-07-26 16:06:12 - src.rule_engine - INFO - rule_engine.py:607 - Rule analysis saved to output/rule_analysis.json
2025-07-26 16:06:12 - __main__ - INFO - main.py:122 -    ‚úì Rule matching completed in 0.02 seconds
2025-07-26 16:06:12 - __main__ - INFO - main.py:123 -    ‚úì Matched 61 rules across 11 fields
2025-07-26 16:06:12 - __main__ - INFO - main.py:124 -    ‚úì Field coverage: 90.9%
2025-07-26 16:06:12 - __main__ - WARNING - main.py:129 -    ‚ö†Ô∏è  1 fields did not match specific rules
2025-07-26 16:06:12 - __main__ - WARNING - main.py:131 -       - Item
2025-07-26 16:06:12 - __main__ - INFO - main.py:134 - 
üßπ STEP 4: Applying cleaning transformations...
2025-07-26 16:06:12 - src.data_cleaner - INFO - data_cleaner.py:43 - Starting data cleaning with confidence threshold: 0.7
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - ERROR - data_cleaner.py:764 - Cleaning error - Rule: standardize_categories, Field: Payment Method, Error: Standardization failed: invalid series dtype: expected `String`, got `f64`
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:12 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:13 - src.data_cleaner - WARNING - data_cleaner.py:432 - Unknown standardization rule: trim_whitespace
2025-07-26 16:06:13 - src.data_cleaner - ERROR - data_cleaner.py:764 - Cleaning error - Rule: handle_missing_numeric, Field: Discount Applied, Error: Missing value handling failed: could not determine supertype of: [bool, dyn int]
2025-07-26 16:06:13 - src.data_cleaner - INFO - data_cleaner.py:64 - Data cleaning completed. Applied 23 operations.
2025-07-26 16:06:13 - src.data_cleaner - INFO - data_cleaner.py:821 - Cleaning report saved to output/cleaning_report.json
2025-07-26 16:06:13 - __main__ - INFO - main.py:159 -    ‚úì Cleaning completed in 0.73 seconds
2025-07-26 16:06:13 - __main__ - INFO - main.py:160 -    ‚úì Performed 23 operations
2025-07-26 16:06:13 - __main__ - INFO - main.py:161 -    ‚úì Affected 121744 records
2025-07-26 16:06:13 - __main__ - WARNING - main.py:164 -    ‚ö†Ô∏è  2 errors encountered
2025-07-26 16:06:13 - __main__ - INFO - main.py:167 - 
üìà STEP 5: Generating quality metrics and monitoring...
2025-07-26 16:06:13 - src.monitoring - INFO - monitoring.py:49 - Starting comprehensive monitoring analysis...
2025-07-26 16:06:13 - src.monitoring - INFO - monitoring.py:78 - Monitoring completed. Generated 3 alerts.
2025-07-26 16:06:13 - src.monitoring - ERROR - monitoring.py:775 - Error generating dashboard: 'DataQualityMonitor' object has no attribute '_get_quality_color'
2025-07-26 16:06:13 - __main__ - ERROR - main.py:249 - Pipeline execution failed: 'DataQualityMonitor' object has no attribute '_get_quality_color'
Traceback (most recent call last):
  File "C:\My Documents\Firstbase_Data Cleaning Project\Firstbase_AI Assessment\Data-Cleaner_Rule-Generator\main.py", line 185, in run_pipeline
    dashboard_path = self.monitor.generate_html_dashboard(
  File "C:\My Documents\Firstbase_Data Cleaning Project\Firstbase_AI Assessment\Data-Cleaner_Rule-Generator\src\monitoring.py", line 764, in generate_html_dashboard
    html_content = self._generate_dashboard_html(monitoring_report, figures)
  File "C:\My Documents\Firstbase_Data Cleaning Project\Firstbase_AI Assessment\Data-Cleaner_Rule-Generator\src\monitoring.py", line 933, in _generate_dashboard_html
    <div class="metric-value quality-{self._get_quality_color(quality_scores.get('completeness', 0))}">{quality_scores.get('completeness', 0):.1%}</div>
AttributeError: 'DataQualityMonitor' object has no attribute '_get_quality_color'
